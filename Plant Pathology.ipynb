{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T, models\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading/Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = Path('./plant-pathology-2020-fgvc7/images')\n",
    "\n",
    "def image_path(file_stem):\n",
    "    return IMAGE_PATH/f'{file_stem}.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./plant-pathology-2020-fgvc7/train.csv')\n",
    "test_df = pd.read_csv('./plant-pathology-2020-fgvc7/test.csv')\n",
    "\n",
    "train_paths = train_df['img_file'] = train_df['image_id'].apply(image_path)\n",
    "test_paths = test_df['img_file'] = test_df['image_id'].apply(image_path)\n",
    "\n",
    "train_labels = train_df[['healthy','multiple_diseases','rust','scab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, valid_paths, train_labels, valid_labels = train_test_split(\n",
    "    train_paths, train_labels, test_size = 0.2, random_state=23, stratify = train_labels)\n",
    "train_paths.reset_index(drop=True,inplace=True)\n",
    "train_labels.reset_index(drop=True,inplace=True)\n",
    "valid_paths.reset_index(drop=True,inplace=True)\n",
    "valid_labels.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafDataset(Data.Dataset):\n",
    "    def __init__(self, img_paths, labels=None, train=True, test=False):\n",
    "        self.img_paths = img_paths\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        \n",
    "        if not self.test:\n",
    "            self.labels = labels\n",
    "        \n",
    "        self.train_transform = T.Compose([T.CenterCrop(256),\n",
    "                                          T.RandomRotation(25),\n",
    "                                          T.RandomHorizontalFlip(),\n",
    "                                          T.RandomVerticalFlip(),])\n",
    "        self.test_transform = T.Compose([T.CenterCrop(256),\n",
    "                                         T.RandomRotation(25),\n",
    "                                         T.RandomHorizontalFlip(),\n",
    "                                         T.RandomVerticalFlip(),])\n",
    "        self.default_transform = T.Compose([T.ToTensor(),\n",
    "                                            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),]) # ImageNet Stats\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.img_paths.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = Image.open(self.img_paths[i]).resize((512, 1))\n",
    "        if not self.test:\n",
    "            label = torch.tensor(np.argmax(self.labels.loc[i, :].values))\n",
    "        if self.train:\n",
    "            image = self.train_transform(image)\n",
    "        elif self.test:\n",
    "            image = self.test_transform(image)\n",
    "        image  = self.default_transform(image)\n",
    "        \n",
    "        \n",
    "        return image, label if not self.test else image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training, validataion and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, data_loader, optim, scheduler, loss_fn, acc_fn):\n",
    "    running_loss = 0\n",
    "    preds_for_acc = []\n",
    "    labels_for_acc = []\n",
    "    \n",
    "    pbar = tqdm(total=len(data_loader), desc='Training')\n",
    "    \n",
    "    for idx, (images, labels) in enumerate(data_loader):\n",
    "        print(f'current training batch: {idx}')\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        print(f'batch_size: {images.shape}')\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        scores = model(images)\n",
    "        loss = loss_fn(scores, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item() * labels.shape[0]\n",
    "        labels_for_acc = np.concatenate((labels_for_acc, labels.cpu().numpy()), 0)\n",
    "        preds_for_acc = np.concatenate(\n",
    "            (preds_for_acc, np.argmax(scores.cpu().detach().numpy(), 1)), 0)\n",
    "        \n",
    "        pbar.update()\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    return running_loss / TRAIN_SIZE, acc_fn(labels_for_acc, preds_for_acc)\n",
    "\n",
    "\n",
    "def validation(model, data_loader, loss_fn, acc_fn, confusion_matrix):\n",
    "     \n",
    "    running_loss = 0\n",
    "    preds_for_acc = []\n",
    "    labels_for_acc = []\n",
    "    \n",
    "    pbar = tqdm(total = len(loader), desc='Validation')\n",
    "    \n",
    "    with torch.no_grad():       #torch.no_grad() prevents Autograd engine from storing intermediate values, saving memory\n",
    "        for idx, (images, labels) in enumerate(loader):\n",
    "            print(f'current validation batch: {idx}')\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            model.eval()\n",
    "            scores = net(images)\n",
    "            loss = loss_fn(scores, labels)\n",
    "            \n",
    "            running_loss += loss.item() * labels.shape[0]\n",
    "            labels_for_acc = np.concatenate((labels_for_acc, labels.cpu().numpy()), 0)\n",
    "            preds_for_acc = np.concatenate((preds_for_acc, np.argmax(scores.cpu().detach().numpy(), 1)), 0)\n",
    "            \n",
    "            pbar.update()\n",
    "            \n",
    "        accuracy = accuracy_fn(labels_for_acc, preds_for_acc)\n",
    "        conf_mat = confusion_matrix(labels_for_acc, preds_for_acc)\n",
    "    \n",
    "    pbar.close()\n",
    "    return running_loss/VALID_SIZE, accuracy, conf_mat\n",
    "\n",
    "\n",
    "def testing(model, data_loader):\n",
    "    \n",
    "    preds_for_output = np.zeros((1,4))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(total = len(loader))\n",
    "        for _, images in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            model.eval()\n",
    "            scores = net(images)\n",
    "            preds_for_output = np.concatenate((preds_for_output, scores.cpu().detach().numpy()), 0)\n",
    "            pbar.update()\n",
    "    \n",
    "    pbar.close()\n",
    "    return preds_for_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 30\n",
    "TRAIN_SIZE = train_labels.shape[0]\n",
    "VALID_SIZE = valid_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LeafDataset(train_paths, train_labels)\n",
    "trainloader = Data.DataLoader(train_dataset, shuffle=True, batch_size = BATCH_SIZE, num_workers = 2)\n",
    "\n",
    "valid_dataset = LeafDataset(valid_paths, valid_labels, train = False)\n",
    "validloader = Data.DataLoader(valid_dataset, shuffle=False, batch_size = BATCH_SIZE, num_workers = 2)\n",
    "\n",
    "test_dataset = LeafDataset(test_paths, train = False, test = True)\n",
    "testloader = Data.DataLoader(test_dataset, shuffle=False, batch_size = BATCH_SIZE, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet161(pretrained=True)\n",
    "densenet.classifier = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(2208),\n",
    "    nn.Linear(2208, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(densenet.parameters(), lr=8e-4, weight_decay = 1e-3)\n",
    "num_train_steps = int(len(train_dataset) / BATCH_SIZE * NUM_EPOCHS)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "model = densenet\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    tl, ta = training(model, trainloader, optimizer, scheduler, loss_fn, accuracy_score)\n",
    "    vl, va, conf_mat = valid_fn(model, validloader, optimizer, scheduler, loss_fn, accuracy_score)\n",
    "    train_loss.append(tl)\n",
    "    valid_loss.append(vl)\n",
    "    train_acc.append(ta)\n",
    "    val_acc.append(va)\n",
    "    \n",
    "    if (epoch+1)%10==0:\n",
    "        path = 'epoch' + str(epoch) + '.pt'\n",
    "        torch.save(model.state_dict(), path)\n",
    "    \n",
    "    printstr = 'Epoch: '+ str(epoch) + ', Train loss: ' + str(tl) + ', Val loss: ' + str(vl) + ', Train acc: ' + str(ta) + ', Val acc: ' + str(va)\n",
    "    tqdm.write(printstr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
